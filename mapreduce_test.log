WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1926531242_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1926531242_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1926531242_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@652c6215
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/wordCount/07161.txt:0+8180
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 12881; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26211044(104844176); length = 3353/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1926531242_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1926531242_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1926531242_0001_m_000000_0: Counters: 17
	File System Counters
		FILE: Number of bytes read=8337
		FILE: Number of bytes written=619530
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=291
		Map output records=839
		Map output bytes=12881
		Map output materialized bytes=14565
		Input split bytes=101
		Combine input records=0
		Spilled Records=839
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=247463936
	File Input Format Counters 
		Bytes Read=8180
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1926531242_0001_m_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1926531242_0001_r_000000_0
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO pool-4-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5656904d
INFO pool-4-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2a4de8dc
WARN pool-4-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=2566809088, maxSingleShuffleLimit=641702272, mergeThreshold=1694094080, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1926531242_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1926531242_0001_m_000000_0 decomp: 14561 len: 14565 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 14561 bytes from map-output for attempt_local1926531242_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 14561, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->14561
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 14558 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 14561 bytes to disk to satisfy reduce memory limit
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 14565 bytes from disk
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 14558 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1926531242_0001_r_000000_0 is done. And is in the process of committing
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1926531242_0001_r_000000_0 is allowed to commit now
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1926531242_0001_r_000000_0' to file:/D:/bigData/wordCount/output
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1926531242_0001_r_000000_0' done.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1926531242_0001_r_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=37499
		FILE: Number of bytes written=638616
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=243
		Reduce shuffle bytes=14565
		Reduce input records=839
		Reduce output records=243
		Spilled Records=839
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=64
		Total committed heap usage (bytes)=198705152
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=4521
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1926531242_0001_r_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1926531242_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1926531242_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=45836
		FILE: Number of bytes written=1258146
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=291
		Map output records=839
		Map output bytes=12881
		Map output materialized bytes=14565
		Input split bytes=101
		Combine input records=0
		Combine output records=0
		Reduce input groups=243
		Reduce shuffle bytes=14565
		Reduce input records=839
		Reduce output records=243
		Spilled Records=1678
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=64
		Total committed heap usage (bytes)=446169088
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=8180
	File Output Format Counters 
		Bytes Written=4521
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1034814420_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1034814420_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1034814420_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@52e9aacd
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/wordCount/07161.txt:0+8180
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 12881; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26211044(104844176); length = 3353/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1034814420_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1034814420_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1034814420_0001_m_000000_0: Counters: 17
	File System Counters
		FILE: Number of bytes read=8337
		FILE: Number of bytes written=619530
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=291
		Map output records=839
		Map output bytes=12881
		Map output materialized bytes=14565
		Input split bytes=101
		Combine input records=0
		Spilled Records=839
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=247463936
	File Input Format Counters 
		Bytes Read=8180
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1034814420_0001_m_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1034814420_0001_r_000000_0
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO pool-4-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2d157920
INFO pool-4-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@755edc29
WARN pool-4-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=2566809088, maxSingleShuffleLimit=641702272, mergeThreshold=1694094080, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1034814420_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1034814420_0001_m_000000_0 decomp: 14561 len: 14565 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 14561 bytes from map-output for attempt_local1034814420_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 14561, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->14561
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 14558 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 14561 bytes to disk to satisfy reduce memory limit
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 14565 bytes from disk
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 14558 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1034814420_0001_r_000000_0 is done. And is in the process of committing
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1034814420_0001_r_000000_0 is allowed to commit now
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1034814420_0001_r_000000_0' to file:/D:/bigData/wordCount/output
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1034814420_0001_r_000000_0' done.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1034814420_0001_r_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=37499
		FILE: Number of bytes written=638616
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=243
		Reduce shuffle bytes=14565
		Reduce input records=839
		Reduce output records=243
		Spilled Records=839
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=70
		Total committed heap usage (bytes)=200802304
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=4521
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1034814420_0001_r_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1034814420_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1034814420_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=45836
		FILE: Number of bytes written=1258146
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=291
		Map output records=839
		Map output bytes=12881
		Map output materialized bytes=14565
		Input split bytes=101
		Combine input records=0
		Combine output records=0
		Reduce input groups=243
		Reduce shuffle bytes=14565
		Reduce input records=839
		Reduce output records=243
		Spilled Records=1678
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=70
		Total committed heap usage (bytes)=448266240
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=8180
	File Output Format Counters 
		Bytes Written=4521
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1623902890_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1623902890_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1623902890_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3baa86e5
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/wordCount/07161.txt:0+8180
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 12881; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26211044(104844176); length = 3353/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1623902890_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1623902890_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1623902890_0001_m_000000_0: Counters: 17
	File System Counters
		FILE: Number of bytes read=8337
		FILE: Number of bytes written=619530
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=291
		Map output records=839
		Map output bytes=12881
		Map output materialized bytes=14565
		Input split bytes=101
		Combine input records=0
		Spilled Records=839
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=247463936
	File Input Format Counters 
		Bytes Read=8180
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1623902890_0001_m_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1623902890_0001_r_000000_0
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO pool-4-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@bb8defb
INFO pool-4-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@75e7b39e
WARN pool-4-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=2566809088, maxSingleShuffleLimit=641702272, mergeThreshold=1694094080, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1623902890_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1623902890_0001_m_000000_0 decomp: 14561 len: 14565 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 14561 bytes from map-output for attempt_local1623902890_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 14561, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->14561
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 14558 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 14561 bytes to disk to satisfy reduce memory limit
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 14565 bytes from disk
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 14558 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1623902890_0001_r_000000_0 is done. And is in the process of committing
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1623902890_0001_r_000000_0 is allowed to commit now
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1623902890_0001_r_000000_0' to file:/D:/bigData/wordCount/output
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1623902890_0001_r_000000_0' done.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1623902890_0001_r_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=37499
		FILE: Number of bytes written=638616
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=243
		Reduce shuffle bytes=14565
		Reduce input records=839
		Reduce output records=243
		Spilled Records=839
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=67
		Total committed heap usage (bytes)=198180864
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=4521
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1623902890_0001_r_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1623902890_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1623902890_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=45836
		FILE: Number of bytes written=1258146
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=291
		Map output records=839
		Map output bytes=12881
		Map output materialized bytes=14565
		Input split bytes=101
		Combine input records=0
		Combine output records=0
		Reduce input groups=243
		Reduce shuffle bytes=14565
		Reduce input records=839
		Reduce output records=243
		Spilled Records=1678
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=67
		Total committed heap usage (bytes)=445644800
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=8180
	File Output Format Counters 
		Bytes Written=4521
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1601396415_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1601396415_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1601396415_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7219eea6
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/wordCount/07161.txt:0+8180
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 12881; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26211044(104844176); length = 3353/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1601396415_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1601396415_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1601396415_0001_m_000000_0: Counters: 18
	File System Counters
		FILE: Number of bytes read=8337
		FILE: Number of bytes written=611843
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=291
		Map output records=839
		Map output bytes=12881
		Map output materialized bytes=6414
		Input split bytes=101
		Combine input records=839
		Combine output records=243
		Spilled Records=243
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=247463936
	File Input Format Counters 
		Bytes Read=8180
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1601396415_0001_m_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1601396415_0001_r_000000_0
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO pool-4-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5bacefab
INFO pool-4-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@247fb15c
WARN pool-4-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=2566809088, maxSingleShuffleLimit=641702272, mergeThreshold=1694094080, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1601396415_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1601396415_0001_m_000000_0 decomp: 6410 len: 6414 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 6410 bytes from map-output for attempt_local1601396415_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 6410, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->6410
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 6407 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 6410 bytes to disk to satisfy reduce memory limit
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 6414 bytes from disk
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 6407 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1601396415_0001_r_000000_0 is done. And is in the process of committing
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1601396415_0001_r_000000_0 is allowed to commit now
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1601396415_0001_r_000000_0' to file:/D:/bigData/wordCount/output
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1601396415_0001_r_000000_0' done.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1601396415_0001_r_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=21197
		FILE: Number of bytes written=622778
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=243
		Reduce shuffle bytes=6414
		Reduce input records=243
		Reduce output records=243
		Spilled Records=243
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=64
		Total committed heap usage (bytes)=196083712
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=4521
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1601396415_0001_r_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1601396415_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1601396415_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=29534
		FILE: Number of bytes written=1234621
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=291
		Map output records=839
		Map output bytes=12881
		Map output materialized bytes=6414
		Input split bytes=101
		Combine input records=839
		Combine output records=243
		Reduce input groups=243
		Reduce shuffle bytes=6414
		Reduce input records=243
		Reduce output records=243
		Spilled Records=486
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=64
		Total committed heap usage (bytes)=443547648
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=8180
	File Output Format Counters 
		Bytes Written=4521
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local2084303948_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local2084303948_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2084303948_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@52e9aacd
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/covid_19_data.csv:0+22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
WARN Thread-4 org.apache.hadoop.mapred.LocalJobRunner - job_local2084303948_0001
java.lang.Exception: java.lang.NumberFormatException: For input string: "Confirmed"
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.lang.NumberFormatException: For input string: "Confirmed"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Long.parseLong(Long.java:589)
	at java.lang.Long.parseLong(Long.java:631)
	at cn.hadoop.mapreduce.covid.sum.CovidSumMapper.map(CovidSumMapper.java:20)
	at cn.hadoop.mapreduce.covid.sum.CovidSumMapper.map(CovidSumMapper.java:9)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local2084303948_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local2084303948_0001 failed with state FAILED due to: NA
INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1782559320_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1782559320_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1782559320_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1cebbb5d
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/covid_19_data.csv:0+22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
WARN Thread-4 org.apache.hadoop.mapred.LocalJobRunner - job_local1782559320_0001
java.lang.Exception: java.lang.NumberFormatException: For input string: "Confirmed"
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.lang.NumberFormatException: For input string: "Confirmed"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Long.parseLong(Long.java:589)
	at java.lang.Long.parseLong(Long.java:631)
	at cn.hadoop.mapreduce.covid.sum.CovidSumMapper.map(CovidSumMapper.java:20)
	at cn.hadoop.mapreduce.covid.sum.CovidSumMapper.map(CovidSumMapper.java:9)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1782559320_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1782559320_0001 failed with state FAILED due to: NA
INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1101060436_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1101060436_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1101060436_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4d9176be
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/wordCount/07161.txt:0+8180
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 12881; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26211044(104844176); length = 3353/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1101060436_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1101060436_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1101060436_0001_m_000000_0: Counters: 18
	File System Counters
		FILE: Number of bytes read=8337
		FILE: Number of bytes written=611843
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=291
		Map output records=839
		Map output bytes=12881
		Map output materialized bytes=6414
		Input split bytes=101
		Combine input records=839
		Combine output records=243
		Spilled Records=243
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=247463936
	File Input Format Counters 
		Bytes Read=8180
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1101060436_0001_m_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1101060436_0001_r_000000_0
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO pool-4-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@127671ab
INFO pool-4-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@555265c0
WARN pool-4-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=2566809088, maxSingleShuffleLimit=641702272, mergeThreshold=1694094080, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1101060436_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1101060436_0001_m_000000_0 decomp: 6410 len: 6414 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 6410 bytes from map-output for attempt_local1101060436_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 6410, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->6410
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 6407 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 6410 bytes to disk to satisfy reduce memory limit
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 6414 bytes from disk
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 6407 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1101060436_0001_r_000000_0 is done. And is in the process of committing
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1101060436_0001_r_000000_0 is allowed to commit now
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1101060436_0001_r_000000_0' to file:/D:/bigData/wordCount/output
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1101060436_0001_r_000000_0' done.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1101060436_0001_r_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=21197
		FILE: Number of bytes written=622778
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=243
		Reduce shuffle bytes=6414
		Reduce input records=243
		Reduce output records=243
		Spilled Records=243
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=69
		Total committed heap usage (bytes)=196608000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=4521
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1101060436_0001_r_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1101060436_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1101060436_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=29534
		FILE: Number of bytes written=1234621
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=291
		Map output records=839
		Map output bytes=12881
		Map output materialized bytes=6414
		Input split bytes=101
		Combine input records=839
		Combine output records=243
		Reduce input groups=243
		Reduce shuffle bytes=6414
		Reduce input records=243
		Reduce output records=243
		Spilled Records=486
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=69
		Total committed heap usage (bytes)=444071936
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=8180
	File Output Format Counters 
		Bytes Written=4521
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local289421857_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local289421857_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local289421857_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@24c99051
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/covid_19_data.csv:0+22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
WARN Thread-4 org.apache.hadoop.mapred.LocalJobRunner - job_local289421857_0001
java.lang.Exception: java.lang.NumberFormatException: For input string: "Confirmed"
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.lang.NumberFormatException: For input string: "Confirmed"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Long.parseLong(Long.java:589)
	at java.lang.Long.parseLong(Long.java:631)
	at cn.hadoop.mapreduce.covid.sum.CovidSumMapper.map(CovidSumMapper.java:20)
	at cn.hadoop.mapreduce.covid.sum.CovidSumMapper.map(CovidSumMapper.java:9)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local289421857_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local289421857_0001 failed with state FAILED due to: NA
INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local540283355_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local540283355_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local540283355_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@374bac01
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/covid_19_data.csv:0+22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
WARN Thread-4 org.apache.hadoop.mapred.LocalJobRunner - job_local540283355_0001
java.lang.Exception: java.lang.NumberFormatException: For input string: "Confirmed"
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.lang.NumberFormatException: For input string: "Confirmed"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Long.parseLong(Long.java:589)
	at java.lang.Long.parseLong(Long.java:631)
	at cn.hadoop.mapreduce.covid.sum.CovidSumMapper.map(CovidSumMapper.java:24)
	at cn.hadoop.mapreduce.covid.sum.CovidSumMapper.map(CovidSumMapper.java:9)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local540283355_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local540283355_0001 failed with state FAILED due to: NA
INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local646603568_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local646603568_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local646603568_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7532c477
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/covid_19_data.csv:0+22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 17; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
WARN Thread-4 org.apache.hadoop.mapred.LocalJobRunner - job_local646603568_0001
java.lang.Exception: java.lang.NumberFormatException: For input string: "1.0"
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.lang.NumberFormatException: For input string: "1.0"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Long.parseLong(Long.java:589)
	at java.lang.Long.parseLong(Long.java:631)
	at cn.hadoop.mapreduce.covid.sum.CovidSumMapper.map(CovidSumMapper.java:24)
	at cn.hadoop.mapreduce.covid.sum.CovidSumMapper.map(CovidSumMapper.java:9)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local646603568_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local646603568_0001 failed with state FAILED due to: NA
INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local571451741_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local571451741_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local571451741_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@41fef468
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/covid_19_data.csv:0+22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 15797; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26212148(104848592); length = 2249/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
WARN Thread-4 org.apache.hadoop.mapred.LocalJobRunner - job_local571451741_0001
java.lang.Exception: java.lang.NumberFormatException: For input string: "2/1/2020 19:43"
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.lang.NumberFormatException: For input string: "2/1/2020 19:43"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at cn.hadoop.mapreduce.covid.sum.CovidSumMapper.map(CovidSumMapper.java:25)
	at cn.hadoop.mapreduce.covid.sum.CovidSumMapper.map(CovidSumMapper.java:9)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local571451741_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local571451741_0001 failed with state FAILED due to: NA
INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local615120898_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local615120898_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local615120898_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@374bac01
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/covid_19_data.csv:0+22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO main org.apache.hadoop.mapreduce.Job - Job job_local615120898_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 7289088; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 24988680(99954720); length = 1225717/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local615120898_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local615120898_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local615120898_0001_m_000000_0: Counters: 17
	File System Counters
		FILE: Number of bytes read=22535468
		FILE: Number of bytes written=8503427
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=306430
		Map output records=306430
		Map output bytes=7289088
		Map output materialized bytes=7901954
		Input split bytes=137
		Combine input records=0
		Spilled Records=306430
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=49
		Total committed heap usage (bytes)=312999936
	File Input Format Counters 
		Bytes Read=22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local615120898_0001_m_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local615120898_0001_r_000000_0
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO pool-4-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@74fc1b6b
INFO pool-4-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@52daca18
WARN pool-4-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=2566809088, maxSingleShuffleLimit=641702272, mergeThreshold=1694094080, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local615120898_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local615120898_0001_m_000000_0 decomp: 7901950 len: 7901954 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 7901950 bytes from map-output for attempt_local615120898_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 7901950, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7901950
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7901947 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 7901950 bytes to disk to satisfy reduce memory limit
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 7901954 bytes from disk
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7901947 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local615120898_0001_r_000000_0 is done. And is in the process of committing
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local615120898_0001_r_000000_0 is allowed to commit now
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local615120898_0001_r_000000_0' to file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/output
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local615120898_0001_r_000000_0' done.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local615120898_0001_r_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=38339408
		FILE: Number of bytes written=16412772
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=276
		Reduce shuffle bytes=7901954
		Reduce input records=306430
		Reduce output records=276
		Spilled Records=306430
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=73
		Total committed heap usage (bytes)=391643136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=7391
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local615120898_0001_r_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local615120898_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=60874876
		FILE: Number of bytes written=24916199
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=306430
		Map output records=306430
		Map output bytes=7289088
		Map output materialized bytes=7901954
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Reduce input groups=276
		Reduce shuffle bytes=7901954
		Reduce input records=306430
		Reduce output records=276
		Spilled Records=612860
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=122
		Total committed heap usage (bytes)=704643072
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=22535273
	File Output Format Counters 
		Bytes Written=7391
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1709355170_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1709355170_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1709355170_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6806e69e
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/covid_19_2.txt:0+22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1709355170_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 7289088; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 24988680(99954720); length = 1225717/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1709355170_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1709355170_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1709355170_0001_m_000000_0: Counters: 17
	File System Counters
		FILE: Number of bytes read=22535465
		FILE: Number of bytes written=8506326
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=306430
		Map output records=306430
		Map output bytes=7289088
		Map output materialized bytes=7901954
		Input split bytes=134
		Combine input records=0
		Spilled Records=306430
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=56
		Total committed heap usage (bytes)=313524224
	File Input Format Counters 
		Bytes Read=22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1709355170_0001_m_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1709355170_0001_r_000000_0
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO pool-4-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@71bfaf06
INFO pool-4-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2a6e08fb
WARN pool-4-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=2566809088, maxSingleShuffleLimit=641702272, mergeThreshold=1694094080, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1709355170_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1709355170_0001_m_000000_0 decomp: 7901950 len: 7901954 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 7901950 bytes from map-output for attempt_local1709355170_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 7901950, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7901950
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7901947 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 7901950 bytes to disk to satisfy reduce memory limit
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 7901954 bytes from disk
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7901947 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1709355170_0001_r_000000_0 is done. And is in the process of committing
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1709355170_0001_r_000000_0 is allowed to commit now
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1709355170_0001_r_000000_0' to file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/output2
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1709355170_0001_r_000000_0' done.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1709355170_0001_r_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=38339405
		FILE: Number of bytes written=16415671
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=276
		Reduce shuffle bytes=7901954
		Reduce input records=306430
		Reduce output records=276
		Spilled Records=306430
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=111
		Total committed heap usage (bytes)=393216000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=7391
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1709355170_0001_r_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1709355170_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=60874870
		FILE: Number of bytes written=24921997
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=306430
		Map output records=306430
		Map output bytes=7289088
		Map output materialized bytes=7901954
		Input split bytes=134
		Combine input records=0
		Combine output records=0
		Reduce input groups=276
		Reduce shuffle bytes=7901954
		Reduce input records=306430
		Reduce output records=276
		Spilled Records=612860
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=167
		Total committed heap usage (bytes)=706740224
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=22535273
	File Output Format Counters 
		Bytes Written=7391
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1854865437_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1854865437_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1854865437_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@374bac01
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/covid_19_2.txt:0+22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1854865437_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 7289088; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 24988680(99954720); length = 1225717/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1854865437_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1854865437_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1854865437_0001_m_000000_0: Counters: 17
	File System Counters
		FILE: Number of bytes read=22535465
		FILE: Number of bytes written=8506326
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=306430
		Map output records=306430
		Map output bytes=7289088
		Map output materialized bytes=7901954
		Input split bytes=134
		Combine input records=0
		Spilled Records=306430
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=50
		Total committed heap usage (bytes)=312999936
	File Input Format Counters 
		Bytes Read=22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1854865437_0001_m_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1854865437_0001_r_000000_0
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO pool-4-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6d3b37cb
INFO pool-4-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2738caa5
WARN pool-4-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=2566809088, maxSingleShuffleLimit=641702272, mergeThreshold=1694094080, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1854865437_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1854865437_0001_m_000000_0 decomp: 7901950 len: 7901954 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 7901950 bytes from map-output for attempt_local1854865437_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 7901950, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7901950
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7901947 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 7901950 bytes to disk to satisfy reduce memory limit
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 7901954 bytes from disk
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7901947 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1854865437_0001_r_000000_0 is done. And is in the process of committing
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1854865437_0001_r_000000_0 is allowed to commit now
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1854865437_0001_r_000000_0' to file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/output2
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1854865437_0001_r_000000_0' done.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1854865437_0001_r_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=38339405
		FILE: Number of bytes written=16415947
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=276
		Reduce shuffle bytes=7901954
		Reduce input records=306430
		Reduce output records=276
		Spilled Records=306430
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=109
		Total committed heap usage (bytes)=392691712
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=7667
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1854865437_0001_r_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1854865437_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=60874870
		FILE: Number of bytes written=24922273
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=306430
		Map output records=306430
		Map output bytes=7289088
		Map output materialized bytes=7901954
		Input split bytes=134
		Combine input records=0
		Combine output records=0
		Reduce input groups=276
		Reduce shuffle bytes=7901954
		Reduce input records=306430
		Reduce output records=276
		Spilled Records=612860
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=159
		Total committed heap usage (bytes)=705691648
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=22535273
	File Output Format Counters 
		Bytes Written=7667
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1114352087_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1114352087_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1114352087_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@39c2c20
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/covid_19_2.txt:0+22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1114352087_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 11010488; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 24988680(99954720); length = 1225717/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1114352087_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1114352087_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1114352087_0001_m_000000_0: Counters: 17
	File System Counters
		FILE: Number of bytes read=22535465
		FILE: Number of bytes written=12227726
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=306430
		Map output records=306430
		Map output bytes=11010488
		Map output materialized bytes=11623354
		Input split bytes=134
		Combine input records=0
		Spilled Records=306430
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=49
		Total committed heap usage (bytes)=312999936
	File Input Format Counters 
		Bytes Read=22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1114352087_0001_m_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1114352087_0001_r_000000_0
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO pool-4-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@60e9ee7d
INFO pool-4-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@15540e71
WARN pool-4-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=2566809088, maxSingleShuffleLimit=641702272, mergeThreshold=1694094080, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1114352087_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1114352087_0001_m_000000_0 decomp: 11623350 len: 11623354 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 11623350 bytes from map-output for attempt_local1114352087_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 11623350, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->11623350
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 11623347 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 11623350 bytes to disk to satisfy reduce memory limit
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 11623354 bytes from disk
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 11623347 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1114352087_0001_r_000000_0 is done. And is in the process of committing
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1114352087_0001_r_000000_0 is allowed to commit now
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1114352087_0001_r_000000_0' to file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/output2
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1114352087_0001_r_000000_0' done.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1114352087_0001_r_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=45782205
		FILE: Number of bytes written=23912018
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=1906
		Reduce shuffle bytes=11623354
		Reduce input records=306430
		Reduce output records=1906
		Spilled Records=306430
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=75
		Total committed heap usage (bytes)=390070272
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=60938
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1114352087_0001_r_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1114352087_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=68317670
		FILE: Number of bytes written=36139744
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=306430
		Map output records=306430
		Map output bytes=11010488
		Map output materialized bytes=11623354
		Input split bytes=134
		Combine input records=0
		Combine output records=0
		Reduce input groups=1906
		Reduce shuffle bytes=11623354
		Reduce input records=306430
		Reduce output records=1906
		Spilled Records=612860
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=124
		Total committed heap usage (bytes)=703070208
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=22535273
	File Output Format Counters 
		Bytes Written=60938
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1087127079_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1087127079_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1087127079_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@41fef468
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/covid_19_2.txt:0+22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1087127079_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 7138636; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 24988680(99954720); length = 1225717/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1087127079_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1087127079_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1087127079_0001_m_000000_0: Counters: 17
	File System Counters
		FILE: Number of bytes read=22535465
		FILE: Number of bytes written=8355874
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=306430
		Map output records=306430
		Map output bytes=7138636
		Map output materialized bytes=7751502
		Input split bytes=134
		Combine input records=0
		Spilled Records=306430
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=56
		Total committed heap usage (bytes)=312999936
	File Input Format Counters 
		Bytes Read=22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1087127079_0001_m_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1087127079_0001_r_000000_0
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO pool-4-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@37036dbc
INFO pool-4-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@417d6ae4
WARN pool-4-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=2566809088, maxSingleShuffleLimit=641702272, mergeThreshold=1694094080, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1087127079_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1087127079_0001_m_000000_0 decomp: 7751498 len: 7751502 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 7751498 bytes from map-output for attempt_local1087127079_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 7751498, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7751498
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7751495 bytes
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 7751498 bytes to disk to satisfy reduce memory limit
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 7751502 bytes from disk
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7751495 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1087127079_0001_r_000000_0 is done. And is in the process of committing
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1087127079_0001_r_000000_0 is allowed to commit now
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1087127079_0001_r_000000_0' to file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/output2
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1087127079_0001_r_000000_0' done.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1087127079_0001_r_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=38038501
		FILE: Number of bytes written=18782727
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=107147
		Reduce shuffle bytes=7751502
		Reduce input records=306430
		Reduce output records=107147
		Spilled Records=306430
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=100
		Total committed heap usage (bytes)=401604608
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=2675351
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1087127079_0001_r_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1087127079_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=60573966
		FILE: Number of bytes written=27138601
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=306430
		Map output records=306430
		Map output bytes=7138636
		Map output materialized bytes=7751502
		Input split bytes=134
		Combine input records=0
		Combine output records=0
		Reduce input groups=107147
		Reduce shuffle bytes=7751502
		Reduce input records=306430
		Reduce output records=107147
		Spilled Records=612860
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=156
		Total committed heap usage (bytes)=714604544
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=22535273
	File Output Format Counters 
		Bytes Written=2675351
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local84784839_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local84784839_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local84784839_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@12130344
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/covid_19_2.txt:0+22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO main org.apache.hadoop.mapreduce.Job - Job job_local84784839_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 11010488; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 24988680(99954720); length = 1225717/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local84784839_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local84784839_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local84784839_0001_m_000000_0: Counters: 17
	File System Counters
		FILE: Number of bytes read=22535465
		FILE: Number of bytes written=12221918
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=306430
		Map output records=306430
		Map output bytes=11010488
		Map output materialized bytes=11623354
		Input split bytes=134
		Combine input records=0
		Spilled Records=306430
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=61
		Total committed heap usage (bytes)=312999936
	File Input Format Counters 
		Bytes Read=22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local84784839_0001_m_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local84784839_0001_r_000000_0
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO pool-4-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@56f0df15
INFO pool-4-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2c5d3a97
WARN pool-4-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=2566809088, maxSingleShuffleLimit=641702272, mergeThreshold=1694094080, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local84784839_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local84784839_0001_m_000000_0 decomp: 11623350 len: 11623354 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 11623350 bytes from map-output for attempt_local84784839_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 11623350, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->11623350
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 11623347 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 11623350 bytes to disk to satisfy reduce memory limit
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 11623354 bytes from disk
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 11623347 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local84784839_0001_r_000000_0 is done. And is in the process of committing
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local84784839_0001_r_000000_0 is allowed to commit now
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local84784839_0001_r_000000_0' to file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/output2
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local84784839_0001_r_000000_0' done.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local84784839_0001_r_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=45782205
		FILE: Number of bytes written=23906210
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=1906
		Reduce shuffle bytes=11623354
		Reduce input records=306430
		Reduce output records=1906
		Spilled Records=306430
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=86
		Total committed heap usage (bytes)=390070272
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=60938
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local84784839_0001_r_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local84784839_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=68317670
		FILE: Number of bytes written=36128128
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=306430
		Map output records=306430
		Map output bytes=11010488
		Map output materialized bytes=11623354
		Input split bytes=134
		Combine input records=0
		Combine output records=0
		Reduce input groups=1906
		Reduce shuffle bytes=11623354
		Reduce input records=306430
		Reduce output records=1906
		Spilled Records=612860
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=147
		Total committed heap usage (bytes)=703070208
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=22535273
	File Output Format Counters 
		Bytes Written=60938
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local585771303_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local585771303_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local585771303_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3baa86e5
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/covid_19_2.txt:0+22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO main org.apache.hadoop.mapreduce.Job - Job job_local585771303_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 7267407; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 24988680(99954720); length = 1225717/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local585771303_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local585771303_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local585771303_0001_m_000000_0: Counters: 17
	File System Counters
		FILE: Number of bytes read=22535465
		FILE: Number of bytes written=8481739
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=306430
		Map output records=306430
		Map output bytes=7267407
		Map output materialized bytes=7880273
		Input split bytes=134
		Combine input records=0
		Spilled Records=306430
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=50
		Total committed heap usage (bytes)=312999936
	File Input Format Counters 
		Bytes Read=22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local585771303_0001_m_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local585771303_0001_r_000000_0
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO pool-4-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6db4a718
INFO pool-4-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@35fa7335
WARN pool-4-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=2566809088, maxSingleShuffleLimit=641702272, mergeThreshold=1694094080, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local585771303_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local585771303_0001_m_000000_0 decomp: 7880269 len: 7880273 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 7880269 bytes from map-output for attempt_local585771303_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 7880269, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7880269
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7880266 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 7880269 bytes to disk to satisfy reduce memory limit
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 7880273 bytes from disk
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7880266 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local585771303_0001_r_000000_0 is done. And is in the process of committing
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local585771303_0001_r_000000_0 is allowed to commit now
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local585771303_0001_r_000000_0' to file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/output2
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local585771303_0001_r_000000_0' done.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local585771303_0001_r_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=38296043
		FILE: Number of bytes written=16368855
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=229
		Reduce shuffle bytes=7880273
		Reduce input records=306430
		Reduce output records=229
		Spilled Records=306430
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=71
		Total committed heap usage (bytes)=392167424
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=6843
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local585771303_0001_r_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local585771303_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=60831508
		FILE: Number of bytes written=24850594
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=306430
		Map output records=306430
		Map output bytes=7267407
		Map output materialized bytes=7880273
		Input split bytes=134
		Combine input records=0
		Combine output records=0
		Reduce input groups=229
		Reduce shuffle bytes=7880273
		Reduce input records=306430
		Reduce output records=229
		Spilled Records=612860
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=121
		Total committed heap usage (bytes)=705167360
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=22535273
	File Output Format Counters 
		Bytes Written=6843
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1227354716_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1227354716_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1227354716_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@52c25586
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/covid_19_data.csv:0+22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1227354716_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 7267407; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 24988680(99954720); length = 1225717/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1227354716_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1227354716_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1227354716_0001_m_000000_0: Counters: 17
	File System Counters
		FILE: Number of bytes read=22535468
		FILE: Number of bytes written=8484652
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=306430
		Map output records=306430
		Map output bytes=7267407
		Map output materialized bytes=7880273
		Input split bytes=137
		Combine input records=0
		Spilled Records=306430
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=54
		Total committed heap usage (bytes)=312999936
	File Input Format Counters 
		Bytes Read=22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1227354716_0001_m_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1227354716_0001_r_000000_0
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO pool-4-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7c3e6a17
INFO pool-4-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@47fc33b
WARN pool-4-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=2566809088, maxSingleShuffleLimit=641702272, mergeThreshold=1694094080, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1227354716_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1227354716_0001_m_000000_0 decomp: 7880269 len: 7880273 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 7880269 bytes from map-output for attempt_local1227354716_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 7880269, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7880269
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7880266 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 7880269 bytes to disk to satisfy reduce memory limit
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 7880273 bytes from disk
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7880266 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1227354716_0001_r_000000_0 is done. And is in the process of committing
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1227354716_0001_r_000000_0 is allowed to commit now
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1227354716_0001_r_000000_0' to file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/output
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1227354716_0001_r_000000_0' done.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1227354716_0001_r_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=38296046
		FILE: Number of bytes written=16371768
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=229
		Reduce shuffle bytes=7880273
		Reduce input records=306430
		Reduce output records=229
		Spilled Records=306430
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=79
		Total committed heap usage (bytes)=392691712
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=6843
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1227354716_0001_r_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1227354716_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=60831514
		FILE: Number of bytes written=24856420
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=306430
		Map output records=306430
		Map output bytes=7267407
		Map output materialized bytes=7880273
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Reduce input groups=229
		Reduce shuffle bytes=7880273
		Reduce input records=306430
		Reduce output records=229
		Spilled Records=612860
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=133
		Total committed heap usage (bytes)=705691648
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=22535273
	File Output Format Counters 
		Bytes Written=6843
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1520599424_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1520599424_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1520599424_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@374bac01
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/covid_19_data.csv:0+22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1520599424_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 7267407; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 24988680(99954720); length = 1225717/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1520599424_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1520599424_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1520599424_0001_m_000000_0: Counters: 17
	File System Counters
		FILE: Number of bytes read=22535468
		FILE: Number of bytes written=8484652
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=306430
		Map output records=306430
		Map output bytes=7267407
		Map output materialized bytes=7880273
		Input split bytes=137
		Combine input records=0
		Spilled Records=306430
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=50
		Total committed heap usage (bytes)=312999936
	File Input Format Counters 
		Bytes Read=22535273
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1520599424_0001_m_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1520599424_0001_r_000000_0
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO pool-4-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@37036dbc
INFO pool-4-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@417d6ae4
WARN pool-4-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=2566809088, maxSingleShuffleLimit=641702272, mergeThreshold=1694094080, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1520599424_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1520599424_0001_m_000000_0 decomp: 7880269 len: 7880273 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 7880269 bytes from map-output for attempt_local1520599424_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 7880269, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7880269
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7880266 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 7880269 bytes to disk to satisfy reduce memory limit
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 7880273 bytes from disk
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-4-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7880266 bytes
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1520599424_0001_r_000000_0 is done. And is in the process of committing
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1520599424_0001_r_000000_0 is allowed to commit now
INFO pool-4-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1520599424_0001_r_000000_0' to file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/output
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1520599424_0001_r_000000_0' done.
INFO pool-4-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1520599424_0001_r_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=38296046
		FILE: Number of bytes written=16371768
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=229
		Reduce shuffle bytes=7880273
		Reduce input records=306430
		Reduce output records=229
		Spilled Records=306430
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=73
		Total committed heap usage (bytes)=390594560
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=6843
INFO pool-4-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1520599424_0001_r_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1520599424_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=60831514
		FILE: Number of bytes written=24856420
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=306430
		Map output records=306430
		Map output bytes=7267407
		Map output materialized bytes=7880273
		Input split bytes=137
		Combine input records=0
		Combine output records=0
		Reduce input groups=229
		Reduce shuffle bytes=7880273
		Reduce input records=306430
		Reduce output records=229
		Spilled Records=612860
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=123
		Total committed heap usage (bytes)=703594496
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=22535273
	File Output Format Counters 
		Bytes Written=6843
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local350190538_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local350190538_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local350190538_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5c1516a4
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/output2/part-r-00000:0+6779
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
WARN Thread-4 org.apache.hadoop.mapred.LocalJobRunner - job_local350190538_0001
java.lang.Exception: java.lang.NumberFormatException: For input string: "0.0   0.0"
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.lang.NumberFormatException: For input string: "0.0   0.0"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at cn.hadoop.mapreduce.covid.sumShort.CovidSortMapper.map(CovidSortMapper.java:19)
	at cn.hadoop.mapreduce.covid.sumShort.CovidSortMapper.map(CovidSortMapper.java:10)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local350190538_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local350190538_0001 failed with state FAILED due to: NA
INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local237258713_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local237258713_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local237258713_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1ff7222f
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/output2/part-r-00000:0+6717
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.fs.FSInputChecker - Found checksum error: b[0, 4096]=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
org.apache.hadoop.fs.ChecksumException: Checksum error: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/output2/part-r-00000 at 0 exp: -238785068 got: 16253982
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:347)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:303)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:252)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:197)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:227)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:185)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:152)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:192)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:568)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
WARN Thread-4 org.apache.hadoop.mapred.LocalJobRunner - job_local237258713_0001
java.lang.Exception: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/output2/part-r-00000 at 0 exp: -238785068 got: 16253982
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/output2/part-r-00000 at 0 exp: -238785068 got: 16253982
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:347)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:303)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:252)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:197)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:227)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:185)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:152)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:192)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:568)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local237258713_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local237258713_0001 failed with state FAILED due to: NA
INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local657920833_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local657920833_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local657920833_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@12586219
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/output2/part-r-00000:0+6717
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.fs.FSInputChecker - Found checksum error: b[0, 4096]=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
org.apache.hadoop.fs.ChecksumException: Checksum error: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/output2/part-r-00000 at 0 exp: -238785068 got: 16253982
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:347)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:303)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:252)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:197)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:227)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:185)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:152)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:192)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:568)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
WARN Thread-4 org.apache.hadoop.mapred.LocalJobRunner - job_local657920833_0001
java.lang.Exception: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/output2/part-r-00000 at 0 exp: -238785068 got: 16253982
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/output2/part-r-00000 at 0 exp: -238785068 got: 16253982
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:347)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:303)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:252)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:197)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:227)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:185)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:152)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:192)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:568)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local657920833_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local657920833_0001 failed with state FAILED due to: NA
INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1095896073_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1095896073_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1095896073_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@51ac1e43
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/output2/part-r-00000:0+6716
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.fs.FSInputChecker - Found checksum error: b[0, 4096]=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
org.apache.hadoop.fs.ChecksumException: Checksum error: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/output2/part-r-00000 at 0 exp: -238785068 got: 225129840
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:347)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:303)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:252)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:197)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:227)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:185)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:152)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:192)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:568)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
WARN Thread-4 org.apache.hadoop.mapred.LocalJobRunner - job_local1095896073_0001
java.lang.Exception: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/output2/part-r-00000 at 0 exp: -238785068 got: 225129840
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/D:/bigData/covidData/NovelCoronaVirus2019Dataset/output2/part-r-00000 at 0 exp: -238785068 got: 225129840
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:347)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:303)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:252)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:197)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:227)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:185)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:152)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:192)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:568)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1095896073_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1095896073_0001 failed with state FAILED due to: NA
INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Cleaning up the staging area file:/tmp/hadoop/mapred/staging/861321648367943/.staging/job_local1648367943_0001
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Cleaning up the staging area file:/tmp/hadoop/mapred/staging/861321062308558/.staging/job_local1062308558_0001
WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local523558825_0001
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local523558825_0001
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local523558825_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3cc07131
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: org.apache.hadoop.mapreduce.lib.db.DBInputFormat$DBInputSplit@7fc5e89
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local523558825_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task attempt_local523558825_0001_m_000000_0 is allowed to commit now
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local523558825_0001_m_000000_0' to file:/D:/bigData/MilitarySize/outputDB
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local523558825_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local523558825_0001_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=122
		FILE: Number of bytes written=603176
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Input split bytes=78
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=154664960
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=640
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local523558825_0001_m_000000_0
INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local523558825_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local523558825_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 15
	File System Counters
		FILE: Number of bytes read=122
		FILE: Number of bytes written=603176
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Input split bytes=78
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=154664960
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=640
